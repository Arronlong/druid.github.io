# 段

德鲁伊将其索引存储在*段文件中*，这些*文件*按时间划分。在基本设置中，对于每个时间间隔，其中所述时间间隔是在所述可配置创建一个分段文件 `segmentGranularity`的参数`granularitySpec`，其是记录[在这里](http://druid.io/docs/0.12.3/ingestion/ingestion-spec.html#granularityspec)。为了让德鲁伊在繁重的查询负载下运行良好，重要的是段文件大小在300mb-700mb的推荐范围内。如果你的段文件大于该范围，然后再考虑要么改变时间间隔的粒度或分区数据，并调整了`targetPartitionSize`您的`partitioningSpec` （一个很好的起点，这个参数是500万行）。请参阅下面的分片部分和[批量摄取](http://druid.io/docs/0.12.3/ingestion/hadoop.html#partitioning-specification)的“分区规范”部分 文档以获取更多信息。

### 段文件的核心数据结构

这里我们描述了段文件的内部结构，它基本上是*列式的*：每列的数据都是在不同的数据结构中布局的。通过分别存储每个列，Druid可以通过仅扫描查询实际需要的列来减少查询延迟。有三种基本列类型：时间戳列，维度列和度量标准列，如下图所示：

![德鲁伊列类型](http://druid.io/docs/img/druid-column-types.png)

时间戳和度量标准列很简单：在幕后，每个列都是使用LZ4压缩的整数或浮点值数组。一旦查询知道它需要选择哪些行，它就会解压缩这些行，拉出相关的行，并应用所需的聚合运算符。与所有列一样，如果查询不需要列，则只会跳过该列的数据。

维度列不同，因为它们支持过滤和分组操作，因此每个维度都需要以下三个数据结构：

1. 将值（总是被视为字符串）映射到整数ID的字典，
2. 列的值列表，使用1中的字典编码，和
3. 对于列中的每个不同值，一个位图指示哪些行包含该值。

为什么这三个数据结构？字典简单地将字符串值映射到整数id，以便可以紧凑地表示2和3中的值。3中的位图 - 也称为*反向索引*允许快速过滤操作（具体而言，位图便于快速应用AND和OR运算符）。最后，*group by*和*TopN* 查询需要2中的值列表。换句话说，仅基于过滤器汇总度量标准的查询不需要触摸存储在2中的维度值列表。

要具体了解这些数据结构，请考虑上面示例数据中的“页面”列。表示此维度的三个数据结构如下图所示。

```text
1: Dictionary that encodes column values
  {
    "Justin Bieber": 0,
    "Ke$ha":         1
  }

2: Column data
  [0,
   0,
   1,
   1]

3: Bitmaps - one for each unique value of the column
  value="Justin Bieber": [1,1,0,0]
  value="Ke$ha":         [0,0,1,1]
```

请注意，位图与前两个数据结构不同：前两个数据结构呈线性增长（在最坏的情况下），位图部分的大小是数据大小*列基数的乘积。压缩将在这里帮助我们，因为我们知道对于“列数据”中的每一行，只有一个具有非零条目的位图。这意味着高基数列将具有非常稀疏且因此高度可压缩的位图。德鲁伊使用特别适用于位图的压缩算法来利用这一点，例如咆哮位图压缩。

### 多值列

如果数据源使用多值列，则段文件中的数据结构看起来有点不同。让我们想象一下，在上面的例子中，第二行被标记为'Ke $ ha'*和* 'Justin Bieber'主题。在这种情况下，三个数据结构现在看起来如下：

```text
1: Dictionary that encodes column values
  {
    "Justin Bieber": 0,
    "Ke$ha":         1
  }

2: Column data
  [0,
   [0,1],  <--Row value of multi-value column can have array of values
   1,
   1]

3: Bitmaps - one for each unique value
  value="Justin Bieber": [1,1,0,0]
  value="Ke$ha":         [0,1,1,1]
                            ^
                            |
                            |
    Multi-value column has multiple non-zero entries
```

请注意列数据中第二行和Ke $ ha位图的更改。如果某行的列具有多个值，则其在“列数据”中的条目是值数组。此外， “列数据”中具有*n* *个*值的行将在位图中具有*n*个非零值条目。

## 命名惯例

段的标识符通常使用段数据源，间隔开始时间（ISO 8601格式），间隔结束时间（ISO 8601格式）和版本构建。如果数据另外分片超出时间范围，则段标识符还将包含分区号。

示例段标识符可以是：datasource_intervalStart_intervalEnd_version_partitionNum

## 细分组件

在幕后，一个片段由几个文件组成，如下所示。

- `version.bin`

  4个字节，表示当前段版本为整数。例如，对于v9段，版本为0x0,0x0,0x0,0x9

- `meta.smoosh`

  包含有关其他`smoosh`文件内容的元数据（文件名和偏移量）的文件

- `XXXXX.smoosh`

  这些文件中有一些是连接的二进制数据

  这些`smoosh`文件代表多个“smooshed”文件，以便最大限度地减少必须打开以容纳数据的文件描述符的数量。它们是最大2GB的文件（以匹配Java中映射的ByteBuffer内存的限制）。这些`smoosh`文件包含数据中每个列的单个文件以及`index.drd`包含有关该段的额外元数据的文件。

  还有一个名为的特殊列`__time`，指的是段的时间列。随着代码的发展，这将变得越来越不特别，但是现在它和我妈妈总是告诉我的一样特别。

在代码库中，段具有内部格式版本。当前的段格式版本是`v9`。

## 列的格式

每列存储为两部分：

1. 杰克逊序列化的ColumnDescriptor
2. 列的其余二进制文件

ColumnDescriptor本质上是一个对象，它允许我们使用jackson的多态反序列化来添加新的和有趣的序列化方法，而对代码的影响最小。它包含一些关于列的元数据（它是什么类型，是多值等），然后是一个serde逻辑列表，可以反序列化二进制文件的其余部分。

## 分片数据以创建分段

### 拆分

对于相同的数据源，可以在相同的时间间隔内存在多个段。这些段形成一个`block`间隔。根据`shardSpec`用于分片数据的类型，德鲁伊查询只有在a `block`完成时才能完成。也就是说，如果一个块由3个段组成，例如：

```
sampleData_2011-01-01T02:00:00:00Z_2011-01-01T03:00:00:00Z_v1_0
sampleData_2011-01-01T02:00:00:00Z_2011-01-01T03:00:00:00Z_v1_1
sampleData_2011-01-01T02:00:00:00Z_2011-01-01T03:00:00:00Z_v1_2
```

在查询间隔`2011-01-01T02:00:00:00Z_2011-01-01T03:00:00:00Z`完成之前，必须加载所有3个段。

此规则的例外是使用线性分片规范。线性分片规范不会强制“完整性”，即使系统中未加载分片，查询也可以完成。例如，如果您的实时摄取创建了3个使用线性分片规范进行分片的片段，并且系统中仅加载了两个片段，则查询将仅返回这两个片段的结果。