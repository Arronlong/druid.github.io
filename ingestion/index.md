# 摄取

## 概观

### 数据源(Datasources)和段(Segment)

德鲁伊数据存储在“Datasources”中，类似于传统RDBMS中的表。每个数据源(Datasources)按时间划分，并可选择进一步按其他属性划分。每个时间范围都称为“块”（例如，如果您的Datasources按天分区，则为一天）。在块中，数据被划分为一个或多个“段”。每个段都是单个文件，通常包含多达几百万行数据。由于段被组织成时间块，因此将段视为生活在时间轴上有时会有所帮助，如下所示：

![img](http://druid.io/docs/img/druid-timeline.png)

数据源(Datasources)可能只有几个段，最多可达数十万甚至数百万个段。每个段都开始在MiddleManager上创建生命，并且在那时，它是可变的和未提交的。分段构建过程包括以下步骤，旨在生成紧凑的数据文件并支持快速查询：

- 转换为柱状格式
- 使用位图索引进行索引
- 使用各种算法进行压缩
  - 字符串编码，使用String列的id存储最小化
  - 位图索引的位图压缩
  - 所有列的类型感知压缩

定期发布（提交）段(segment)。此时，它们被写入深层存储，变为不可变，并从MiddleManagers转移到Historical进程。关于该段的条目也被写入元数据存储。此条目是有关该段的自描述元数据，包括段的架构，其大小以及它在深层存储上的位置。这些条目是协调器用于了解群集上*应该*有哪些数据的用途。

有关段文件格式的详细信息，请参阅[段文件](http://druid.io/docs/0.12.3/design/segments.html)。

#### 段(segment)标识符

分段都具有包含以下组件的四部分标识符：

- 数据源(Datasources)名称。
- 时间间隔（包含段的时间块;这对应`segmentGranularity`于摄取时指定的时间）。
- 版本号（通常是与首次启动段集时对应的ISO8601时间戳）。
- 分区号（一个整数，在数据源(Datasources)中唯一+区间+版本;可能不一定是连续的）。

例如，这是数据源(Datasources)`clarity-cloud0`，时间块 `2018-05-21T16:00:00.000Z/2018-05-21T17:00:00.000Z`，版本`2018-05-21T15:56:09.909Z`和分区号1中的段的标识符：

```text
clarity-cloud0_2018-05-21T16:00:00.000Z_2018-05-21T17:00:00.000Z_2018-05-21T15:56:09.909Z_1
```

分区号为0的分段（块中的第一个分区）省略分区号，如下例所示，它是与前一个分块在同一时间块中的分段，但分区号为0而不是1：

```text
clarity-cloud0_2018-05-21T16:00:00.000Z_2018-05-21T17:00:00.000Z_2018-05-21T15:56:09.909Z
```

#### 段(segment)版本

您可能想知道上一节中描述的“版本号”是什么。或者，你可能不是，在这种情况下对你有好处，你可以跳过这一节！

它支持批量模式覆盖。在德鲁伊，如果您所做的只是附加数据，那么每个时间块只会有一个版本。但是当您覆盖数据时，幕后发生的事情是使用相同的数据源(Datasources)，相同的时间间隔创建一组新的段，但版本号更高。这是对德鲁伊系统其余部分的一个信号，即应该从群集中删除旧版本，新版本应该替换它。

切换似乎是瞬间发生在用户身上，因为德鲁伊通过首先加载新数据（但不允许查询）来处理这个问题，然后，一旦新数据全部加载，切换所有新查询以使用这些新段(segment)。然后它在几分钟后掉落旧的段。

#### 段(segment)状态

段可以是*可用的*或*不可用的*，这是指它们是否是由一些德鲁伊服务器进程目前担任。它们也可以*发布*或未*发布*，这是指它们是否已写入深层存储和元数据存储。并公布部分可以是*二手*或*闲置*，这是指小德是否不认为它们应投放有效的区隔。

将这些放在一起，一个段(segment)可以有五个基本状态：

- **已发布，可用和已使用：**这些段在深层存储和元数据存储中发布，它们由历史进程提供。它们是德鲁伊集群中的大多数活动数据（它们包括除了飞行中实时数据之外的所有数据）。
- **已发布，可用和未使用：**这些段由Historicals提供，但不会持续很长时间。它们可能是最近被覆盖的[段](http://druid.io/docs/0.12.3/ingestion/index.html#segment-versioning)（请参阅[段版本控制](http://druid.io/docs/0.12.3/ingestion/index.html#segment-versioning)）或由于其他原因（例如删除规则或手动删除）而丢弃的段。
- **已发布，不可用和已使用：**这些段在深层存储和元数据存储中发布， *应该*提供，但实际上并未提供。如果段保持这种状态超过几分钟，通常是因为出了问题。一些更常见的原因包括：大量历史记录失败，历史记录超出下载更多段的能力，以及一些协调问题阻止协调员告知历史记录加载新段。
- **已发布，不可用和未使用：**这些段在深层存储和元数据存储中发布，但处于非活动状态（因为它们已被覆盖或删除）。它们处于休眠状态，如果需要，可以通过手动操作复活（特别是：将“used”标志设置为true）。
- **未发布和可用：**这是段由德鲁伊摄取任务构建时所处的状态。这包括尚未传递给历史的所有“实时”数据。处于此状态的段可能会也可能不会被复制。如果所有副本都丢失，则必须从头开始重建该段。这可能是也可能是不可能的。（这是可能与卡夫卡，和自动发生;它可以与S3 / HDFS通过重新启动作业;并且它是*不*可能的宁静，所以在这种情况下，数据将丢失。）

该矩阵中的第六个状态“未发布且不可用”是不可能的。如果某个段(segment)未发布且未投放，那么它确实存在吗？

#### 索引和切换

*索引*是创建新段的机制，*切换*是发布它们并开始由历史进程提供服务的机制。该机制在索引方面的工作原理如下：

1. 一个*索引任务*开始运行，并建立一个新的段(segment)市场。它必须在开始构建之前确定该段的标识符。对于附加的任务（如Kafka任务或附加模式中的索引任务），这将通过在Overlord上调用“allocate”API来潜在地将新分区添加到现有的一组段来完成。对于覆盖的任务（如Hadoop任务或*不在*追加模式下的索引任务），可通过锁定间隔并创建新版本号和新的段集来完成。
2. 如果索引任务是实时任务（如Kafka任务），则此时可立即查询该段。它可用，但未发表。
3. 当索引任务完成读取段的数据时，它会将其推送到深层存储，然后通过将记录写入元数据存储来发布它。
4. 如果索引任务是实时任务，则此时它等待历史进程加载该段。如果索引任务不是实时任务，则会立即退出。

在协调员/历史方面这样：

1. 协调器定期轮询元数据存储（默认情况下，每1分钟一次），用于新发布的段。
2. 当协调器找到已发布和使用但不可用的段时，它会选择历史进程来加载该段并指示历史记录执行此操作。
3. 历史记录加载该段并开始为其提供服务。
4. 此时，如果索引任务正在等待切换，它将退出。

## 摄取方法

在大多数摄取方法中，这项工作由Druid MiddleManager节点完成。一个例外是基于Hadoop的摄取，其中这项工作是使用YARN上的Hadoop MapReduce作业完成的（尽管MiddleManager节点仍然参与启动和监视Hadoop作业）。

一旦生成了段并将其存储在[深层存储中](http://druid.io/docs/0.12.3/dependencies/deep-storage.html)，它们将由Druid Historical节点加载。一些德鲁伊摄取方法还支持*实时查询*，这意味着您可以在完成转换并写入深存储之前在MiddleManager节点上查询正在运行的数据。通常，相对于从Historical节点提供的大量历史数据，将在MiddleManager节点上传输少量数据。

有关Druid如何存储和管理数据的更多详细信息，请参见[设计](http://druid.io/docs/0.12.3/design/index.html)页面。

下表列出了德鲁伊最常见的数据提取方法，以及帮助您根据自己的情况选择最佳数据的比较。

| 方法                                                         | 这个怎么运作                                              | 可以附加和覆盖吗？ | 可以处理后期数据？  | 完全一次摄入？            | 实时查询？ |
| ------------------------------------------------------------ | --------------------------------------------------------- | ------------------ | ------------------- | ------------------------- | ---------- |
| [原生批次](http://druid.io/docs/0.12.3/ingestion/native-batch.html) | Druid直接从S3，HTTP，NFS或其他网络存储加载数据。          | 追加或覆盖         | 是                  | 是                        | 没有       |
| [Hadoop的](http://druid.io/docs/0.12.3/ingestion/hadoop.html) | Druid启动Hadoop Map / Reduce作业以加载数据文件。          | 追加或覆盖         | 是                  | 是                        | 没有       |
| [卡夫卡索引服务](http://druid.io/docs/0.12.3/development/extensions-core/kafka-ingestion.html) | 德鲁伊直接从卡夫卡读。                                    | 仅附加             | 是                  | 是                        | 是         |
| [宁静](http://druid.io/docs/0.12.3/ingestion/stream-push.html) | 您使用Tranquility（一个客户端库）将个人记录推送到德鲁伊。 | 仅附加             | 否 - 延迟数据被删除 | 否 - 可能会丢弃或复制数据 | 是         |

## 分区

Druid是一个分布式数据存储，它会对您的数据进行分区，以便并行处理它。德鲁伊 [数据源(Datasources)](http://druid.io/docs/0.12.3/design/index.html)总是首先根据摄取规范的[segmentGranularity](http://druid.io/docs/0.12.3/ingestion/index.html#granularityspec)参数按时间划分 。这些时间分区中的每一个都称为*时间块*，每次块都包含一个或多个[段](http://druid.io/docs/0.12.3/design/segments.html)。特定时间块内的段可以使用根据您选择的摄取方法而变化的选项进一步分区。

- 使用[Hadoop，](http://druid.io/docs/0.12.3/ingestion/hadoop.html)您可以在一列或多列上执行基于散列或基于范围的分区。
- 使用[Native批处理，](http://druid.io/docs/0.12.3/ingestion/native-batch.html)您可以对所有维列的哈希进行分区。启用汇总时这很有用，因为它可以最大限度地节省空间。
- 使用[Kafka索引时](http://druid.io/docs/0.12.3/development/extensions-core/kafka-ingestion.html)，分区基于Kafka分区，并且无法通过Druid进行配置。您可以使用Kafka生产者的分区功能在Kafka端配置它。
- 在[Tranquility中](http://druid.io/docs/0.12.3/ingestion/stream-push.html)，默认情况下，在所有维列的哈希上完成分区，以便最大化汇总。您还可以提供自定义的Partitioner类; 有关详细信息，请参阅 [Tranquility文档](https://github.com/druid-io/tranquility/blob/master/docs/overview.md#partitioning-and-replication)。

所有德鲁伊数据源(Datasources)都按时间划分。每个数据摄取方法在加载数据时必须在特定时间范围内获取写锁定，因此没有两种方法可以同时在同一数据源(Datasources)的同一时间范围内操作。但是，两种数据摄取方法*可以*同时在同一数据源(Datasources)的不同时间范围内运行。例如，您可以从Hadoop执行批量回填，同时还可以从Kafka进行实时加载，只要回填数据和实时数据不需要写入同一时间分区即可。（如果他们这样做，实时负载将优先。）

## 卷起

德鲁伊能够使用我们称之为“累积”的过程在摄取时间汇总原始数据。汇总是对选定的一组“维度”进行的第一级聚合操作，其中聚合了一组“度量”。

假设我们有以下原始数据，表示源和目标之间流量的特定秒的总数据包/字节数。的`srcIP`和`dstIP`字段的尺寸，而`packets`与`bytes`是指标。

```text
timestamp                 srcIP         dstIP          packets     bytes
2018-01-01T01:01:35Z      1.1.1.1       2.2.2.2            100      1000
2018-01-01T01:01:51Z      1.1.1.1       2.2.2.2            200      2000
2018-01-01T01:01:59Z      1.1.1.1       2.2.2.2            300      3000
2018-01-01T01:02:14Z      1.1.1.1       2.2.2.2            400      4000
2018-01-01T01:02:29Z      1.1.1.1       2.2.2.2            500      5000
2018-01-01T01:03:29Z      1.1.1.1       2.2.2.2            600      6000
2018-01-02T21:33:14Z      7.7.7.7       8.8.8.8            100      1000
2018-01-02T21:33:45Z      7.7.7.7       8.8.8.8            200      2000
2018-01-02T21:35:45Z      7.7.7.7       8.8.8.8            300      3000
```

如果我们用这种摄取到的数据德鲁伊`queryGranularity`的`minute`（这将地板时间戳分钟），卷起操作等效于以下伪代码：

```text
GROUP BY TRUNCATE(timestamp, MINUTE), srcIP, dstIP :: SUM(packets), SUM(bytes)
```

在汇总期间聚合上述数据后，将接收以下行：

```text
timestamp                 srcIP         dstIP          packets     bytes
2018-01-01T01:01:00Z      1.1.1.1       2.2.2.2            600      6000
2018-01-01T01:02:00Z      1.1.1.1       2.2.2.2            900      9000
2018-01-01T01:03:00Z      1.1.1.1       2.2.2.2            600      6000
2018-01-02T21:33:00Z      7.7.7.7       8.8.8.8            300      3000
2018-01-02T21:35:00Z      7.7.7.7       8.8.8.8            300      3000
```

德鲁伊可以在摄取数据时汇总数据，以最大限度地减少需要存储的原始数据量。在实践中，我们看到汇总数据可以大大减少需要存储的数据的大小（最多100倍）。这种存储减少确实需要付出代价：当我们汇总数据时，我们将无法查询单个事件。

汇总粒度是您将能够探索数据的最小粒度，并且事件将被覆盖到此粒度。因此，德鲁伊摄取规范将此粒度定义为`queryGranularity`数据。支持的最低值`queryGranularity`是毫秒。

以下链接可能有助于进一步了解维度和指标：* https://en.wikipedia.org/wiki/Dimension_(data_warehouse）* https://en.wikipedia.org/wiki/Measure_(data_warehouse））

### 上卷模式

德鲁伊支持两种卷起模式，即*完美的卷起*和*尽力而为的卷起*。在完美的汇总模式中，德鲁伊保证输入数据在摄取时间内完美聚合。同时，在尽力而为的汇总中，输入数据可能不会被完美地聚合，因此可以存在多个段，这些段保持应该属于同一段的行具有完美的汇总，因为它们具有相同的维度值并且时间戳落入相同的时间间隔。

完美的汇总模式包含一个额外的预处理步骤，如果未在ingestionSpec中指定，则在实际数据摄取之前确定间隔和shardSpec。此预处理步骤通常会扫描整个输入数据，这可能会增加摄取时间。在[Hadoop的索引任务](http://druid.io/docs/0.12.3/ingestion/hadoop.html)总是与这个完美卷起模式下运行。

相反，尽力而为的汇总模式不需要任何预处理步骤，但摄取数据的大小可能大于完美汇总的大小。所有类型的[流索引（例如，kafka索引服务）](http://druid.io/docs/0.12.3/ingestion/stream-ingestion.html)都以此模式运行。

最后，本[机索引任务](http://druid.io/docs/0.12.3/ingestion/native-batch.html)支持这两种模式，您可以选择适合您的应用程序的模式。

## 数据维护

### 插入和覆盖

德鲁伊可以通过将新段附加到现有段集来将新数据插入现有数据源(Datasources)。它还可以通过将现有的一组段与新数据合并并覆盖原始集来添加新数据。

德鲁伊不支持主键的单记录更新。

[更新现有数据时](http://druid.io/docs/0.12.3/ingestion/update-existing-data.html)将进一步描述[更新](http://druid.io/docs/0.12.3/ingestion/update-existing-data.html)。

### 压实

压缩是一种覆盖操作，它读取现有的一组段，将它们组合成一个具有更大但更少段的新集，并用新压缩集覆盖原始集，而不更改存储的数据。

出于性能原因，将一组段压缩为一组较大但较少的段有时是有益的，因为在摄取和查询路径中存在一些每段处理和存储器开销。

有关压缩文档，请参阅[任务](http://druid.io/docs/0.12.3/ingestion/compaction.html)。

### 保留和分层

Druid支持保留规则，用于定义应保留数据的时间间隔，以及应丢弃数据的间隔。

Druid还支持将历史节点分成层，并且可以配置保留规则以将特定间隔的数据分配给特定层。

这些功能对性能/成本管理很有用; 一个常见的用例是将历史节点分为“热”层和“冷”层。

有关更多信息，请参阅[加载规则](http://druid.io/docs/0.12.3/operations/rule-configuration.html)。

### 删除

Druid支持永久删除处于“未使用”状态的[段](http://druid.io/docs/0.12.3/ingestion/index.html#segment-states)（请参阅上面的[段状态](http://druid.io/docs/0.12.3/ingestion/index.html#segment-states)部分）。

Kill Task从元数据存储和深层存储中删除指定时间间隔内未使用的段。

有关更多信息，请参阅“ [杀死任务”](http://druid.io/docs/0.12.3/ingestion/tasks.html#kill-task)。